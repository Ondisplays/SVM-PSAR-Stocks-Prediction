{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9EShvoP96s1"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENXTvHmgRIyB"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwF_IfwFawl2"
      },
      "source": [
        "Instalisasi Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxB7DCV2fPV6",
        "outputId": "9c62ba2b-2810-4556-f96a-6f8079b544f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mplfinance\n",
            "  Downloading mplfinance-0.12.10b0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mplfinance) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from mplfinance) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mplfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->mplfinance) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->mplfinance) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mplfinance) (1.17.0)\n",
            "Downloading mplfinance-0.12.10b0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.10b0\n"
          ]
        }
      ],
      "source": [
        "!pip install mplfinance\n",
        "!pip install yfinance\n",
        "!pip install backtesting\n",
        "!pip install plotly\n",
        "!pip install vectorbt\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install pandas-ta\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DftZd0G2RMsa"
      },
      "source": [
        "# Data Gathering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpBn_KFMaMyM"
      },
      "source": [
        "Download Saham dalam 3 Waktu Sekaligus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMSKuheYf6FH"
      },
      "outputs": [],
      "source": [
        "#Pengambiland Dataset Dari YFInance\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "# Parameter\n",
        "ticker = \"ADRO.JK\"\n",
        "start_date1 = \"2019-01-01\"\n",
        "end_date = \"2024-01-01\"\n",
        "interval = \"1d\"\n",
        "\n",
        "# Ambil data BYAN.JK dalam periode 5 tahun\n",
        "data_saham_1= yf.download(ticker, start=start_date1, end=end_date, interval=interval, auto_adjust=False, multi_level_index=False)\n",
        "\n",
        "# Tampilkan data\n",
        "data_saham_1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2hyeFUzRQ1-"
      },
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmu6V1NfbBOu"
      },
      "source": [
        "Implementasi Parabolic SAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7uzNk-6gYup"
      },
      "outputs": [],
      "source": [
        "import fileinput\n",
        "\n",
        "file_path = \"/usr/local/lib/python3.11/dist-packages/pandas_ta/momentum/squeeze_pro.py\"\n",
        "\n",
        "with fileinput.FileInput(file_path, inplace=True, backup='.bak') as file:\n",
        "    for line in file:\n",
        "        print(line.replace(\"from numpy import NaN as npNaN\", \"from numpy import nan as npNaN\"), end='')\n",
        "\n",
        "#Implementasi Teknikal Indikator\n",
        "import pandas_ta as ta\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Implementasi Parabolic SAR\n",
        "psar = ta.psar(high=data_saham_1['High'], low=data_saham_1['Low'], close=data_saham_1['Close'], af=0.02, max_af=0.2)\n",
        "data_saham_1 = pd.concat([data_saham_1, psar.add_suffix('_PSAR')], axis=1)\n",
        "\n",
        "\n",
        "data_saham_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_9pBN_xbFW4"
      },
      "source": [
        "Penerapan Look Up Day Close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BExnQ373gdbf"
      },
      "outputs": [],
      "source": [
        "#Look up day close\n",
        "#\n",
        "lookup_day = 10\n",
        "\n",
        "data_saham_1['lookup_day_close'] = data_saham_1['Close'].shift(-lookup_day)\n",
        "\n",
        "data_saham_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPKZ8KBnbJFV"
      },
      "source": [
        "Penerapan Label Buy/Hold/Sell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HYzTrHJglUJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Target profit dan loss\n",
        "target_profit = 0.08\n",
        "target_loss = -0.04\n",
        "\n",
        "# Fungsi untuk labeling\n",
        "def apply_label(row):\n",
        "    selisih = (row['lookup_day_close'] - row['Close']) / row['Close']\n",
        "    if selisih > target_profit:\n",
        "        return \"Buy\"\n",
        "    elif selisih < target_loss:\n",
        "        return \"Sell\"\n",
        "    else:\n",
        "        return \"Hold\"\n",
        "\n",
        "# Terapkan ke data_saham_1\n",
        "data_saham_1['label'] = data_saham_1.apply(apply_label, axis=1)\n",
        "\n",
        "# Tampilkan data yang sudah dilabel\n",
        "data_saham_1[['Close', 'lookup_day_close', 'label']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LLofhrHbdTs"
      },
      "source": [
        "Penerapan Fitur dan Filter PSAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOXeYcpVbcD2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#  Filter: Sinyal perpindahan titik PSAR\n",
        "def psar_shift_signal(row):\n",
        "    if row['psar_trend'] == 1 and row['psar_trend_prev'] == -1:\n",
        "        return 1  # Perpindahan ke atas (Bearish reversal)\n",
        "    elif row['psar_trend'] == -1 and row['psar_trend_prev'] == 1:\n",
        "        return -1  # Perpindahan ke bawah (Bullish reversal)\n",
        "    else:\n",
        "        return 0  # Tidak ada perubahan\n",
        "\n",
        "#  Hitung trend PSAR\n",
        "def detect_trend(row):\n",
        "    psarl = row['PSARl_0.02_0.2_PSAR']\n",
        "    psars = row['PSARs_0.02_0.2_PSAR']\n",
        "\n",
        "    if not pd.isna(psarl) and pd.isna(psars):\n",
        "        return 1  # Tren naik (Bullish)\n",
        "    elif pd.isna(psarl) and not pd.isna(psars):\n",
        "        return -1  # Tren turun (Bearish)\n",
        "    else:\n",
        "        return 0  # Tidak berubah\n",
        "\n",
        "#  Gabungkan PSAR atas dan bawah\n",
        "def gabungkan_psar(row):\n",
        "    psarl = row['PSARl_0.02_0.2_PSAR']\n",
        "    psars = row['PSARs_0.02_0.2_PSAR']\n",
        "\n",
        "    if pd.isna(psarl):\n",
        "        return psars\n",
        "    elif pd.isna(psars):\n",
        "        return psarl\n",
        "    else:\n",
        "        return psarl\n",
        "\n",
        "#  Mulai proses pada data_saham_1\n",
        "df = data_saham_1.copy()  # Hindari SettingWithCopyWarning\n",
        "\n",
        "# Hapus kolom duplikat kalau ada\n",
        "df = df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "# Proses PSAR\n",
        "df['psar_trend'] = df.apply(detect_trend, axis=1)\n",
        "df['psar_trend_prev'] = df['psar_trend'].shift(1)\n",
        "df['psar_shift'] = df.apply(psar_shift_signal, axis=1)\n",
        "df['PSAR'] = df.apply(gabungkan_psar, axis=1)\n",
        "df['d1'] = df['Close'] - df['PSAR']\n",
        "df['d2'] = df['d1'] - df['d1'].shift(1)\n",
        "\n",
        "# Jika terjadi perpindahan titik PSAR, samakan nilai d2 dengan sebelumnya\n",
        "for j in range(1, len(df)):\n",
        "    if df.loc[df.index[j], 'psar_shift'] != 0:\n",
        "        df.loc[df.index[j], 'd2'] = df.loc[df.index[j-1], 'd2']\n",
        "\n",
        "# Simpan kembali ke variabel utama\n",
        "data_saham_1 = df\n",
        "\n",
        "# Cek hasil\n",
        "data_saham_1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk5ZdXLzbrRN"
      },
      "source": [
        "Drop Nilai NaN dalam dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y88bSyk5gnNP"
      },
      "outputs": [],
      "source": [
        "df = data_saham_1\n",
        "\n",
        "df_final = df[['Close', 'd1', 'd2', 'psar_shift']]\n",
        "target = df['label']\n",
        "\n",
        "df_final_clean = df_final.dropna()\n",
        "target_clean = target.loc[df_final_clean.index]\n",
        "\n",
        "data_saham_final_1 = df_final_clean\n",
        "target_1 = target_clean\n",
        "\n",
        "print(type(data_saham_final_1))\n",
        "\n",
        "data_saham_final_1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33PWkO0mbx8g"
      },
      "source": [
        "Pembagian Dataset dan Balacing Data menggunakan SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ySKAf4DlFWW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#  Dataset dan target yang sudah diproses (data_saham_final_1 harus sudah siap sebelumnya)\n",
        "data = data_saham_final_1  # Data fitur\n",
        "target = target_1          # Label target\n",
        "data.index = pd.to_datetime(data.index)\n",
        "\n",
        "#  Definisikan rolling windows\n",
        "windows = [\n",
        "    (\"2019-01-01\", \"2022-01-01\"),\n",
        "    (\"2020-01-01\", \"2023-01-01\"),\n",
        "    (\"2021-01-01\", \"2023-06-01\"),\n",
        "]\n",
        "\n",
        "X_trains, X_tests, y_trains, y_tests = [], [], [], []\n",
        "\n",
        "#  Simpan label untuk plotting\n",
        "labels_before, labels_after = [], []\n",
        "\n",
        "#  Loop untuk rolling windows\n",
        "for i, (start_train, end_train) in enumerate(windows):\n",
        "    # Train dan test berdasarkan tanggal\n",
        "    X_train = data.loc[start_train:end_train]\n",
        "    y_train = target.loc[start_train:end_train]\n",
        "    X_test = data.loc[end_train:\"2024-01-01\"]\n",
        "    y_test = target.loc[end_train:\"2024-01-01\"]\n",
        "\n",
        "    # Simpan label sebelum SMOTE untuk plot\n",
        "    labels_before.append(y_train)\n",
        "\n",
        "    # SMOTE\n",
        "    smote = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=2)\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Simpan label setelah SMOTE untuk plot\n",
        "    labels_after.append(y_train_resampled)\n",
        "\n",
        "    # Simpan hasil\n",
        "    X_trains.append(X_train_resampled)\n",
        "    y_trains.append(y_train_resampled)\n",
        "    X_tests.append(X_test)\n",
        "    y_tests.append(y_test)\n",
        "\n",
        "#  Visualisasi distribusi sebelum dan sesudah SMOTE\n",
        "df_labels = pd.DataFrame({\n",
        "    'Dataset': sum([[f'Rolling {i+1}'] * len(y) for i, y in enumerate(labels_before)], []),\n",
        "    'Label': pd.concat(labels_before)\n",
        "})\n",
        "\n",
        "df_labels_after = pd.DataFrame({\n",
        "    'Dataset': sum([[f'Rolling {i+1}'] * len(y) for i, y in enumerate(labels_after)], []),\n",
        "    'Label': pd.concat(labels_after)\n",
        "})\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Sebelum SMOTE\n",
        "sns.countplot(y='Label', hue='Dataset', data=df_labels, palette='Set2', ax=axes[0])\n",
        "axes[0].set_title(\"Distribusi Label Sebelum SMOTE\")\n",
        "axes[0].set_xlabel(\"Jumlah\")\n",
        "axes[0].set_ylabel(\"Kategori\")\n",
        "axes[0].legend(title=\"Dataset\")\n",
        "axes[0].spines[['top', 'right']].set_visible(False)\n",
        "\n",
        "# Setelah SMOTE\n",
        "sns.countplot(y='Label', hue='Dataset', data=df_labels_after, palette='Set2', ax=axes[1])\n",
        "axes[1].set_title(\"Distribusi Label Setelah SMOTE\")\n",
        "axes[1].set_xlabel(\"Jumlah\")\n",
        "axes[1].set_ylabel(\"\")\n",
        "axes[1].legend(title=\"Dataset\")\n",
        "axes[1].spines[['top', 'right']].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgIh-XwFb4KP"
      },
      "source": [
        "Normalisasi menggunakan Standar Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouPOJgn_erHm"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "#  Gunakan hasil dari proses SMOTE sebelumnya\n",
        "# (X_trains, X_tests, y_trains, y_tests sudah tersedia dari kode pertama)\n",
        "\n",
        "#  Buat nama-nama dataset untuk logging\n",
        "dataset_names = [f\"Rolling {i+1}\" for i in range(len(X_trains))]\n",
        "\n",
        "#  Simpan hasil standardisasi\n",
        "X_train_scaled_list, X_test_scaled_list = [], []\n",
        "\n",
        "#  Loop untuk setiap dataset rolling\n",
        "for X_train_resampled, X_test, name in zip(X_trains, X_tests, dataset_names):\n",
        "    print(f\"🔹 Proses standardisasi untuk {name}...\")\n",
        "\n",
        "    # Inisialisasi StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Standardisasi pada data training (fit + transform)\n",
        "    X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
        "\n",
        "    # Transformasi pada data testing (transform saja)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Simpan hasil\n",
        "    X_train_scaled_list.append(X_train_scaled)\n",
        "    X_test_scaled_list.append(X_test_scaled)\n",
        "\n",
        "    print(f\"✅ Selesai untuk {name}\\n\")\n",
        "\n",
        "#  Assign ke variabel terpisah agar mudah digunakan\n",
        "X_train_1_scaled, X_train_2_scaled, X_train_3_scaled = X_train_scaled_list\n",
        "X_test_1_scaled, X_test_2_scaled, X_test_3_scaled = X_test_scaled_list\n",
        "\n",
        "#  Assign juga untuk y_train dari hasil SMOTE\n",
        "y_train_1_resampled, y_train_2_resampled, y_train_3_resampled = y_trains\n",
        "y_test_1, y_test_2, y_test_3 = y_tests\n",
        "\n",
        "#  Output hasil\n",
        "print(\"✅ Semua dataset selesai diproses dengan standardisasi StandardScaler.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql4L2JuXRbl8"
      },
      "source": [
        "# SVM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DGOwGnFb8rf"
      },
      "source": [
        "Penggunaan Grid Search untuk mencari nilai parameter terbaik pada setiap model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri0VHuqogtJH"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#  Definisi parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
        "    'gamma': [1, 0.5, 0.1, 0.05],\n",
        "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
        "}\n",
        "\n",
        "#  Inisialisasi variabel model kosong\n",
        "svm_model_1 = None\n",
        "svm_model_2 = None\n",
        "svm_model_3 = None\n",
        "\n",
        "#  Simpan juga hasil terbaik\n",
        "best_params_dict = {}\n",
        "\n",
        "#  Loop untuk masing-masing rolling window\n",
        "for i, (X_train_scaled, y_train_resampled, name) in enumerate(zip(X_train_scaled_list, y_trains, dataset_names), start=1):\n",
        "    print(f\" Training SVM untuk {name} (rolling window {i})...\")\n",
        "\n",
        "    svm_model = GridSearchCV(\n",
        "        estimator=SVC(),\n",
        "        param_grid=param_grid,\n",
        "        refit=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    svm_model.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "    # Simpan ke variabel spesifik per rolling window\n",
        "    if i == 1:\n",
        "        svm_model_1 = svm_model\n",
        "    elif i == 2:\n",
        "        svm_model_2 = svm_model\n",
        "    elif i == 3:\n",
        "        svm_model_3 = svm_model\n",
        "\n",
        "    # Simpan hasil terbaik ke dictionary\n",
        "    model_key = f\"data_saham_{i}\"\n",
        "    best_params_dict[model_key] = {\n",
        "        \"Best Parameters\": svm_model.best_params_,\n",
        "        \"Best Estimator\": svm_model.best_estimator_,\n",
        "        \"Best Score\": svm_model.best_score_\n",
        "    }\n",
        "\n",
        "    print(f\"✅ Model untuk {model_key} selesai.\\n\")\n",
        "\n",
        "# 🔹 Menampilkan hasil terbaik\n",
        "print(\" Hasil GridSearchCV (Model yang Berbeda per Rolling):\")\n",
        "for key, best_params in best_params_dict.items():\n",
        "    print(f\" {key}\")\n",
        "    print(\"Best Parameters:\", best_params[\"Best Parameters\"])\n",
        "    print(\"Best Estimator:\", best_params[\"Best Estimator\"])\n",
        "    print(\"Best Score:\", best_params[\"Best Score\"])\n",
        "    print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC_5ZW7CcGHi"
      },
      "source": [
        "Menyimpan Nilai Parameter kedalam data Saham"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTcuUHlfQW65"
      },
      "outputs": [],
      "source": [
        "#  Dictionary hasil terbaik dengan struktur per rolling\n",
        "best_params_dict = {\n",
        "    \"data_saham_1\": {\n",
        "        \"Best Parameters\": svm_model_1.best_params_,\n",
        "        \"Best Estimator\": svm_model_1.best_estimator_,\n",
        "        \"Best Score\": svm_model_1.best_score_\n",
        "    },\n",
        "    \"data_saham_2\": {\n",
        "        \"Best Parameters\": svm_model_2.best_params_,\n",
        "        \"Best Estimator\": svm_model_2.best_estimator_,\n",
        "        \"Best Score\": svm_model_2.best_score_\n",
        "    },\n",
        "    \"data_saham_3\": {\n",
        "        \"Best Parameters\": svm_model_3.best_params_,\n",
        "        \"Best Estimator\": svm_model_3.best_estimator_,\n",
        "        \"Best Score\": svm_model_3.best_score_\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41tfpLgYRgey"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eEuNUqVVvOt"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.heatmap(data_saham_final_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ykd4RhscSCi"
      },
      "source": [
        "Evaluasi Model memakai Accuracy, Classification Report, dan Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ska4E78gyR_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  List dataset yang akan diuji\n",
        "datasets_test = [X_test_1_scaled, X_test_2_scaled, X_test_3_scaled]\n",
        "targets_test = [y_test_1, y_test_2, y_test_3]\n",
        "dataset_names = ['data_saham_1', 'data_saham_2', 'data_saham_3']\n",
        "\n",
        "#  Evaluasi Model SVM untuk setiap dataset\n",
        "for i, (X_test, y_test, name) in enumerate(zip(datasets_test, targets_test, dataset_names)):\n",
        "    print(f\" Evaluasi Model untuk {name}...\\n\")\n",
        "\n",
        "    # Prediksi hasil menggunakan model terbaik dari GridSearchCV\n",
        "    best_model = best_params_dict[name][\"Best Estimator\"]\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=['Buy', 'Hold', 'Sell'],\n",
        "                yticklabels=['Buy', 'Hold', 'Sell'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(f'Confusion Matrix - {name}')\n",
        "    plt.show()\n",
        "\n",
        "    # Accuracy & Classification Report\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\" Accuracy for {name}: {accuracy:.4f}\\n\")\n",
        "    print(f\" Classification Report for {name}:\\n\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uksQUdaaRlLF"
      },
      "source": [
        "# Backtesting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlDWlwnzcZ_Y"
      },
      "source": [
        "Pengetesan Backtesting menggunakan model 1, 2, dan 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4r2kqLpBPKAk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from backtesting import Backtest, Strategy\n",
        "\n",
        "# Download Data Saham\n",
        "data = yf.download(\"ADRO.JK\", start=\"2024-01-01\", end=\"2024-12-31\", auto_adjust=False, multi_level_index=False)\n",
        "\n",
        "# Pastikan hanya mengambil kolom yang diperlukan\n",
        "data_f = data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "data_f.dropna()\n",
        "\n",
        "# Implementasi Parabolic SAR0\n",
        "psar = ta.psar(high=data_f['High'], low=data_f['Low'], close=data_f['Close'], af=0.02, max_af=0.2)\n",
        "data_f = pd.concat([data_f, psar.add_suffix('_PSAR')], axis=1)\n",
        "# Fungsi mendeteksi tren PSAR\n",
        "def detect_trend(row):\n",
        "    if not pd.isna(row['PSARl_0.02_0.2_PSAR']) and pd.isna(row['PSARs_0.02_0.2_PSAR']):\n",
        "        return 1  # Tren naik (Bullish)\n",
        "    elif pd.isna(row['PSARl_0.02_0.2_PSAR']) and not pd.isna(row['PSARs_0.02_0.2_PSAR']):\n",
        "        return -1  # Tren turun (Bearish)\n",
        "    else:\n",
        "        return 0  # Tidak berubah\n",
        "\n",
        "# Tambahkan kolom tren PSAR\n",
        "data_f['psar_trend'] = data_f.apply(detect_trend, axis=1)\n",
        "data_f['psar_trend_prev'] = data_f['psar_trend'].shift(1)\n",
        "data_f['psar_shift'] = np.where((data_f['psar_trend'] != data_f['psar_trend_prev']), data_f['psar_trend'], 0)\n",
        "\n",
        "data_f['PSAR'] = data_f[['PSARl_0.02_0.2_PSAR', 'PSARs_0.02_0.2_PSAR']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "data_f['d1'] = data_f['Close'] - data_f['PSAR']\n",
        "data_f['d2'] = data_f['d1'].diff()\n",
        "\n",
        "data_f = data_f[['Close', 'd1', 'd2', 'psar_shift']].dropna()\n",
        "\n",
        "# Standardisasi dengan sigmoid\n",
        "# def sigmoid_standardization(data):\n",
        "#     return 1 / (1 + np.exp(-data))\n",
        "\n",
        "# Standardisasi dengan StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled_df = pd.DataFrame(scaler.fit_transform(data_f), columns=data_f.columns, index=data_f.index)\n",
        "\n",
        "data = data.loc[data_f.index]\n",
        "\n",
        "# Menggunakan model SVM yang telah dilatih sebelumnya\n",
        "svm_models = [svm_model_1, svm_model_2, svm_model_3]\n",
        "\n",
        "data['Signal_1'] = svm_model_1.predict(X_scaled_df)\n",
        "data['Signal_2'] = svm_model_2.predict(X_scaled_df)\n",
        "data['Signal_3'] = svm_model_3.predict(X_scaled_df)\n",
        "\n",
        "map_signal = {1: \"Buy\", 0: \"Hold\", -1: \"Sell\"}\n",
        "\n",
        "# # Strategi Backtest\n",
        "def run_backtest(signal_column):\n",
        "    class TradeStrategy(Strategy):\n",
        "        def init(self):\n",
        "            pass\n",
        "\n",
        "        def next(self):\n",
        "            i = len(self.data) - 1\n",
        "            current_signal = self.data.df[signal_column].iloc[i]\n",
        "            current_price = self.data.Close[-1]\n",
        "            # 0.97 = 3%, 1,06 = 6% | 0.95 = 5% , 1,10 = 10%\n",
        "            stop_loss_price = current_price * 0.92\n",
        "            take_profit_price = current_price * 1.04\n",
        "            if current_signal == \"Buy\" and not self.position.is_long:\n",
        "              self.buy()\n",
        "              # self.buy(sl=stop_loss_price, tp=take_profit_price)\n",
        "              # self.buy(sl=stop_loss_price)\n",
        "            elif current_signal == \"Sell\" and self.position.is_long:\n",
        "              self.position.close()\n",
        "\n",
        "    # Pastikan indentasi ini sejajar dengan `class FixedTradeStrategy`\n",
        "    data_bt = data[['Open', 'High', 'Low', 'Close', 'Volume', signal_column]]\n",
        "    bt = Backtest(data_bt, TradeStrategy, cash=1_000_000, commission=0.0002, exclusive_orders=True)\n",
        "    return bt.run(), bt\n",
        "\n",
        "# Jalankan Backtest untuk masing-masing model\n",
        "results_1, bt_1 = run_backtest('Signal_1')\n",
        "results_2, bt_2 = run_backtest('Signal_2')\n",
        "results_3, bt_3 = run_backtest('Signal_3')\n",
        "\n",
        "print(\"\\n Hasil Backtest untuk Model 1:\")\n",
        "print(results_1)\n",
        "bt_1.plot()\n",
        "\n",
        "print(\"\\n Hasil Backtest untuk Model 2:\")\n",
        "print(results_2)\n",
        "bt_2.plot()\n",
        "\n",
        "print(\"\\n Hasil Backtest untuk Model 3:\")\n",
        "print(results_3)\n",
        "bt_3.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezWSxNmZwihL"
      },
      "source": [
        "Backtesting dengan Stoploss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e_aI2ZMb5lJl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from backtesting import Backtest, Strategy\n",
        "\n",
        "# Download Data Saham\n",
        "data = yf.download(\"ADRO.JK\", start=\"2024-01-01\", end=\"2024-12-31\", auto_adjust=False, multi_level_index=False)\n",
        "\n",
        "# Pastikan hanya mengambil kolom yang diperlukan\n",
        "data_f = data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "data_f.dropna()\n",
        "\n",
        "# Implementasi Parabolic SAR0\n",
        "psar = ta.psar(high=data_f['High'], low=data_f['Low'], close=data_f['Close'], af=0.02, max_af=0.2)\n",
        "data_f = pd.concat([data_f, psar.add_suffix('_PSAR')], axis=1)\n",
        "# Fungsi mendeteksi tren PSAR\n",
        "def detect_trend(row):\n",
        "    if not pd.isna(row['PSARl_0.02_0.2_PSAR']) and pd.isna(row['PSARs_0.02_0.2_PSAR']):\n",
        "        return 1  # Tren naik (Bullish)\n",
        "    elif pd.isna(row['PSARl_0.02_0.2_PSAR']) and not pd.isna(row['PSARs_0.02_0.2_PSAR']):\n",
        "        return -1  # Tren turun (Bearish)\n",
        "    else:\n",
        "        return 0  # Tidak berubah\n",
        "\n",
        "# Tambahkan kolom tren PSAR\n",
        "data_f['psar_trend'] = data_f.apply(detect_trend, axis=1)\n",
        "data_f['psar_trend_prev'] = data_f['psar_trend'].shift(1)\n",
        "data_f['psar_shift'] = np.where((data_f['psar_trend'] != data_f['psar_trend_prev']), data_f['psar_trend'], 0)\n",
        "\n",
        "data_f['PSAR'] = data_f[['PSARl_0.02_0.2_PSAR', 'PSARs_0.02_0.2_PSAR']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "data_f['d1'] = data_f['Close'] - data_f['PSAR']\n",
        "data_f['d2'] = data_f['d1'].diff()\n",
        "\n",
        "data_f = data_f[['Close', 'd1', 'd2', 'psar_shift']].dropna()\n",
        "\n",
        "# Standardisasi dengan sigmoid\n",
        "# def sigmoid_standardization(data):\n",
        "#     return 1 / (1 + np.exp(-data))\n",
        "\n",
        "# Standardisasi dengan StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled_df = pd.DataFrame(scaler.fit_transform(data_f), columns=data_f.columns, index=data_f.index)\n",
        "\n",
        "data = data.loc[data_f.index]\n",
        "\n",
        "# Menggunakan model SVM yang telah dilatih sebelumnya\n",
        "svm_models = [svm_model_1, svm_model_2, svm_model_3]\n",
        "\n",
        "data['Signal_1'] = svm_model_1.predict(X_scaled_df)\n",
        "data['Signal_2'] = svm_model_2.predict(X_scaled_df)\n",
        "data['Signal_3'] = svm_model_3.predict(X_scaled_df)\n",
        "\n",
        "map_signal = {1: \"Buy\", 0: \"Hold\", -1: \"Sell\"}\n",
        "\n",
        "# # Strategi Backtest\n",
        "def run_backtest(signal_column):\n",
        "    class TradeStrategy(Strategy):\n",
        "        def init(self):\n",
        "            pass\n",
        "\n",
        "        def next(self):\n",
        "            i = len(self.data) - 1\n",
        "            current_signal = self.data.df[signal_column].iloc[i]\n",
        "            current_price = self.data.Close[-1]\n",
        "            # 0.97 = 3%, 1,06 = 6% | 0.95 = 5% , 1,10 = 10%\n",
        "            stop_loss_price = current_price * 0.92\n",
        "            take_profit_price = current_price * 1.04\n",
        "            if current_signal == \"Buy\" and not self.position.is_long:\n",
        "              # self.buy()\n",
        "              # self.buy(sl=stop_loss_price, tp=take_profit_price)\n",
        "              self.buy(sl=stop_loss_price)\n",
        "            elif current_signal == \"Sell\" and self.position.is_long:\n",
        "              self.position.close()\n",
        "\n",
        "    # Pastikan indentasi ini sejajar dengan `class FixedTradeStrategy`\n",
        "    data_bt = data[['Open', 'High', 'Low', 'Close', 'Volume', signal_column]]\n",
        "    bt = Backtest(data_bt, TradeStrategy, cash=1_000_000, commission=0.0002, exclusive_orders=True)\n",
        "    return bt.run(), bt\n",
        "\n",
        "# Jalankan Backtest untuk masing-masing model\n",
        "results_1, bt_1 = run_backtest('Signal_1')\n",
        "results_2, bt_2 = run_backtest('Signal_2')\n",
        "results_3, bt_3 = run_backtest('Signal_3')\n",
        "\n",
        "print(\"\\n Hasil Backtest untuk Model 1:\")\n",
        "print(results_1)\n",
        "bt_1.plot()\n",
        "\n",
        "print(\"\\n Hasil Backtest untuk Model 2:\")\n",
        "print(results_2)\n",
        "bt_2.plot()\n",
        "\n",
        "print(\"\\n Hasil Backtest untuk Model 3:\")\n",
        "print(results_3)\n",
        "bt_3.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glTwuInuwnj6"
      },
      "source": [
        "Backtesting dengan takeprofit dan stoploss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EpgXv3_DIe8q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from backtesting import Backtest, Strategy\n",
        "\n",
        "# Download Data Saham\n",
        "data = yf.download(\"ADRO.JK\", start=\"2024-01-01\", end=\"2024-12-31\", auto_adjust=False, multi_level_index=False)\n",
        "\n",
        "# Pastikan hanya mengambil kolom yang diperlukan\n",
        "data_f = data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "data_f.dropna()\n",
        "\n",
        "# Implementasi Parabolic SAR0\n",
        "psar = ta.psar(high=data_f['High'], low=data_f['Low'], close=data_f['Close'], af=0.02, max_af=0.2)\n",
        "data_f = pd.concat([data_f, psar.add_suffix('_PSAR')], axis=1)\n",
        "# Fungsi mendeteksi tren PSAR\n",
        "def detect_trend(row):\n",
        "    if not pd.isna(row['PSARl_0.02_0.2_PSAR']) and pd.isna(row['PSARs_0.02_0.2_PSAR']):\n",
        "        return 1  # Tren naik (Bullish)\n",
        "    elif pd.isna(row['PSARl_0.02_0.2_PSAR']) and not pd.isna(row['PSARs_0.02_0.2_PSAR']):\n",
        "        return -1  # Tren turun (Bearish)\n",
        "    else:\n",
        "        return 0  # Tidak berubah\n",
        "\n",
        "# Tambahkan kolom tren PSAR\n",
        "data_f['psar_trend'] = data_f.apply(detect_trend, axis=1)\n",
        "data_f['psar_trend_prev'] = data_f['psar_trend'].shift(1)\n",
        "data_f['psar_shift'] = np.where((data_f['psar_trend'] != data_f['psar_trend_prev']), data_f['psar_trend'], 0)\n",
        "\n",
        "data_f['PSAR'] = data_f[['PSARl_0.02_0.2_PSAR', 'PSARs_0.02_0.2_PSAR']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "data_f['d1'] = data_f['Close'] - data_f['PSAR']\n",
        "data_f['d2'] = data_f['d1'].diff()\n",
        "\n",
        "data_f = data_f[['Close', 'd1', 'd2', 'psar_shift']].dropna()\n",
        "\n",
        "# Standardisasi dengan sigmoid\n",
        "# def sigmoid_standardization(data):\n",
        "#     return 1 / (1 + np.exp(-data))\n",
        "\n",
        "# Standardisasi dengan StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled_df = pd.DataFrame(scaler.fit_transform(data_f), columns=data_f.columns, index=data_f.index)\n",
        "\n",
        "data = data.loc[data_f.index]\n",
        "\n",
        "# Menggunakan model SVM yang telah dilatih sebelumnya\n",
        "svm_models = [svm_model_1, svm_model_2, svm_model_3]\n",
        "\n",
        "data['Signal_1'] = svm_model_1.predict(X_scaled_df)\n",
        "data['Signal_2'] = svm_model_2.predict(X_scaled_df)\n",
        "data['Signal_3'] = svm_model_3.predict(X_scaled_df)\n",
        "\n",
        "map_signal = {1: \"Buy\", 0: \"Hold\", -1: \"Sell\"}\n",
        "\n",
        "# # Strategi Backtest\n",
        "def run_backtest(signal_column):\n",
        "    class TradeStrategy(Strategy):\n",
        "        def init(self):\n",
        "            pass\n",
        "\n",
        "        def next(self):\n",
        "            i = len(self.data) - 1\n",
        "            current_signal = self.data.df[signal_column].iloc[i]\n",
        "            current_price = self.data.Close[-1]\n",
        "            # 0.97 = 3%, 1,06 = 6% | 0.95 = 5% , 1,10 = 10%\n",
        "            stop_loss_price = current_price * 0.92\n",
        "            take_profit_price = current_price * 1.04\n",
        "            if current_signal == \"Buy\" and not self.position.is_long:\n",
        "              # self.buy()\n",
        "              self.buy(sl=stop_loss_price, tp=take_profit_price)\n",
        "              # self.buy(sl=stop_loss_price)\n",
        "            elif current_signal == \"Sell\" and self.position.is_long:\n",
        "              self.position.close()\n",
        "\n",
        "    # Pastikan indentasi ini sejajar dengan `class FixedTradeStrategy`\n",
        "    data_bt = data[['Open', 'High', 'Low', 'Close', 'Volume', signal_column]]\n",
        "    bt = Backtest(data_bt, TradeStrategy, cash=1_000_000, commission=0.0002, exclusive_orders=True)\n",
        "    return bt.run(), bt\n",
        "\n",
        "# Jalankan Backtest untuk masing-masing model\n",
        "results_1, bt_1 = run_backtest('Signal_1')\n",
        "results_2, bt_2 = run_backtest('Signal_2')\n",
        "results_3, bt_3 = run_backtest('Signal_3')\n",
        "\n",
        "print(\"\\n Hasil Backtest untuk Model 1:\")\n",
        "print(results_1)\n",
        "bt_1.plot()\n",
        "\n",
        "print(\"\\n Hasil Backtest untuk Model 2:\")\n",
        "print(results_2)\n",
        "bt_2.plot()\n",
        "\n",
        "print(\"\\n Hasil Backtest untuk Model 3:\")\n",
        "print(results_3)\n",
        "bt_3.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "buk17260Pvaj"
      },
      "outputs": [],
      "source": [
        "results_1[\"_trades\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWeJbK33PijO"
      },
      "source": [
        "Melihat dalam bentuk Candle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jEOOMldbp5y5"
      },
      "outputs": [],
      "source": [
        "import mplfinance as mpf\n",
        "\n",
        "# Ambil posisi buy/sell dari hasil backtest\n",
        "trades = results_1['_trades']\n",
        "# Konversi buy/sell dates ke datetime\n",
        "buy_dates = pd.to_datetime(trades.loc[trades['Size'] > 0, 'EntryTime'])\n",
        "sell_dates = pd.to_datetime(trades.loc[trades['Size'] < 0, 'ExitTime'])\n",
        "\n",
        "# Pastikan semua tanggal ada di index data\n",
        "buy_prices = data.loc[data.index.isin(buy_dates), 'Close']\n",
        "sell_prices = data.loc[data.index.isin(sell_dates), 'Close']\n",
        "\n",
        "\n",
        "# Pastikan indeks datetime dan urutan benar\n",
        "ohlc = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "ohlc.index = pd.to_datetime(ohlc.index)\n",
        "ohlc = ohlc.sort_index()\n",
        "\n",
        "# Buat tanda pada grafik\n",
        "apds = []\n",
        "\n",
        "# Plot tanda Buy (↑)\n",
        "if not buy_prices.empty:\n",
        "    buy_plot = pd.Series(np.nan, index=ohlc.index)\n",
        "    buy_plot[buy_prices.index] = buy_prices.values\n",
        "    apds.append(\n",
        "        mpf.make_addplot(buy_plot, type='scatter',\n",
        "                         markersize=100, marker='^', color='lime')\n",
        "    )\n",
        "\n",
        "# Plot tanda Sell (↓)\n",
        "if not sell_prices.empty:\n",
        "    sell_plot = pd.Series(np.nan, index=ohlc.index)\n",
        "    sell_plot[sell_prices.index] = sell_prices.values\n",
        "    apds.append(\n",
        "        mpf.make_addplot(sell_plot, type='scatter',\n",
        "                         markersize=100, marker='v', color='red')\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# Plot chart\n",
        "mpf.plot(ohlc, type='candle', style='yahoo',\n",
        "         title='Sinyal Buy/Sell dari Backtest',\n",
        "         volume=True, addplot=apds, figratio=(16, 9))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0NZY4XkS8fHE"
      },
      "outputs": [],
      "source": [
        "import mplfinance as mpf\n",
        "\n",
        "# Ambil posisi buy/sell dari hasil backtest\n",
        "trades = results_2['_trades']\n",
        "# Konversi buy/sell dates ke datetime\n",
        "buy_dates = pd.to_datetime(trades.loc[trades['Size'] > 0, 'EntryTime'])\n",
        "sell_dates = pd.to_datetime(trades.loc[trades['Size'] < 0, 'ExitTime'])\n",
        "\n",
        "# Pastikan semua tanggal ada di index data\n",
        "buy_prices = data.loc[data.index.isin(buy_dates), 'Close']\n",
        "sell_prices = data.loc[data.index.isin(sell_dates), 'Close']\n",
        "\n",
        "\n",
        "# Pastikan indeks datetime dan urutan benar\n",
        "ohlc = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "ohlc.index = pd.to_datetime(ohlc.index)\n",
        "ohlc = ohlc.sort_index()\n",
        "\n",
        "# Buat tanda pada grafik\n",
        "apds = []\n",
        "\n",
        "# Plot tanda Buy (↑)\n",
        "if not buy_prices.empty:\n",
        "    buy_plot = pd.Series(np.nan, index=ohlc.index)\n",
        "    buy_plot[buy_prices.index] = buy_prices.values\n",
        "    apds.append(\n",
        "        mpf.make_addplot(buy_plot, type='scatter',\n",
        "                         markersize=100, marker='^', color='lime')\n",
        "    )\n",
        "\n",
        "# Plot tanda Sell (↓)\n",
        "if not sell_prices.empty:\n",
        "    sell_plot = pd.Series(np.nan, index=ohlc.index)\n",
        "    sell_plot[sell_prices.index] = sell_prices.values\n",
        "    apds.append(\n",
        "        mpf.make_addplot(sell_plot, type='scatter',\n",
        "                         markersize=100, marker='v', color='red')\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# Plot chart\n",
        "mpf.plot(ohlc, type='candle', style='yahoo',\n",
        "         title='Sinyal Buy/Sell dari Backtest',\n",
        "         volume=True, addplot=apds, figratio=(16, 9))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XsDMA2qM8h1N"
      },
      "outputs": [],
      "source": [
        "import mplfinance as mpf\n",
        "\n",
        "# Ambil posisi buy/sell dari hasil backtest\n",
        "trades = results_3['_trades']\n",
        "# Konversi buy/sell dates ke datetime\n",
        "buy_dates = pd.to_datetime(trades.loc[trades['Size'] > 0, 'EntryTime'])\n",
        "sell_dates = pd.to_datetime(trades.loc[trades['Size'] < 0, 'ExitTime'])\n",
        "\n",
        "# Pastikan semua tanggal ada di index data\n",
        "buy_prices = data.loc[data.index.isin(buy_dates), 'Close']\n",
        "sell_prices = data.loc[data.index.isin(sell_dates), 'Close']\n",
        "\n",
        "\n",
        "# Pastikan indeks datetime dan urutan benar\n",
        "ohlc = data[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "ohlc.index = pd.to_datetime(ohlc.index)\n",
        "ohlc = ohlc.sort_index()\n",
        "\n",
        "# Buat tanda pada grafik\n",
        "apds = []\n",
        "\n",
        "# Plot tanda Buy (↑)\n",
        "if not buy_prices.empty:\n",
        "    buy_plot = pd.Series(np.nan, index=ohlc.index)\n",
        "    buy_plot[buy_prices.index] = buy_prices.values\n",
        "    apds.append(\n",
        "        mpf.make_addplot(buy_plot, type='scatter',\n",
        "                         markersize=100, marker='^', color='lime')\n",
        "    )\n",
        "\n",
        "# Plot tanda Sell (↓)\n",
        "if not sell_prices.empty:\n",
        "    sell_plot = pd.Series(np.nan, index=ohlc.index)\n",
        "    sell_plot[sell_prices.index] = sell_prices.values\n",
        "    apds.append(\n",
        "        mpf.make_addplot(sell_plot, type='scatter',\n",
        "                         markersize=100, marker='v', color='red')\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# Plot chart\n",
        "mpf.plot(ohlc, type='candle', style='yahoo',\n",
        "         title='Sinyal Buy/Sell dari Backtest',\n",
        "         volume=True, addplot=apds, figratio=(16, 9))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ENXTvHmgRIyB"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}